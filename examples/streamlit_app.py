"""
Streamlit Webç•Œé¢
ä¸ºDeep Search Agentæä¾›å‹å¥½çš„Webç•Œé¢
"""

import os
import sys
import streamlit as st
from datetime import datetime
import json
from fpdf import FPDF
try:
    import markdown as md  # ç”¨äºå°†Markdownè½¬ä¸ºHTML
except Exception:
    md = None
from fpdf.html import HTMLMixin
import urllib.request

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src import DeepSearchAgent, Config


# å†å²è®°å½•æ•°æ®åº“è·¯å¾„ï¼ˆæŒ‡å‘é¡¹ç›®æ ¹ç›®å½•ï¼‰
HISTORY_DB_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "history.db"))

# PDFä¸­æ–‡å­—ä½“é…ç½®
FONT_DIR = os.path.join(os.path.dirname(__file__), "fonts")
FONT_PATH = os.path.join(FONT_DIR, "NotoSansCJKsc-Regular.otf")
FONT_DOWNLOAD_URL = "https://github.com/googlefonts/noto-cjk/raw/main/Sans/OTF/SimplifiedChinese/NotoSansCJKsc-Regular.otf"


def ensure_chinese_font():
    """ç¡®ä¿å­˜åœ¨æ”¯æŒä¸­æ–‡çš„å­—ä½“æ–‡ä»¶"""
    if os.path.exists(FONT_PATH):
        return True, None
    try:
        os.makedirs(FONT_DIR, exist_ok=True)
        urllib.request.urlretrieve(FONT_DOWNLOAD_URL, FONT_PATH)
        return True, None
    except Exception as e:
        return False, str(e)


class PDF(FPDF, HTMLMixin):
    pass


def generate_pdf_report(content: str):
    """ä½¿ç”¨FPDFç”Ÿæˆæ”¯æŒä¸­æ–‡çš„PDFæŠ¥å‘Š"""
    font_ready, font_error = ensure_chinese_font()
    if not font_ready:
        return None, f"ä¸‹è½½ä¸­æ–‡å­—ä½“å¤±è´¥: {font_error}"
    try:
        pdf = PDF(orientation="P", unit="mm", format="A4")
        # ç»Ÿä¸€è®¾ç½®é¡µè¾¹è·ï¼Œç¡®ä¿æœ‰æ•ˆå®½åº¦å……è¶³
        pdf.set_margins(left=12, top=15, right=12)
        pdf.add_font("NotoSansSC", "", FONT_PATH, uni=True)
        pdf.set_auto_page_break(auto=True, margin=15)
        pdf.add_page()
        # åŠ¨æ€é€‰æ‹©å®‰å…¨å­—ä½“å¤§å°ï¼Œé¿å…å•å­—ç¬¦ä¹Ÿæ— æ³•æ”¾ä¸‹çš„æƒ…å†µ
        def choose_font_size() -> int:
            size = 12
            effective_width = pdf.w - pdf.l_margin - pdf.r_margin
            # é€‰æ‹©ä»£è¡¨æ€§çš„ä¸­è‹±æ–‡å­—ç¬¦è¿›è¡Œå®½åº¦æµ‹è¯•
            test_chars = ["æ±‰", "W"]
            while size >= 7:
                pdf.set_font("NotoSansSC", size=size)
                if max(pdf.get_string_width(ch) for ch in test_chars) < effective_width:
                    return size
                size -= 1
            return 7
        base_size = choose_font_size()
        pdf.set_font("NotoSansSC", size=base_size)
        line_height = base_size * 0.6  # åˆç†çš„è¡Œé«˜
        effective_width = pdf.w - pdf.l_margin - pdf.r_margin
        # ä¼˜å…ˆï¼šå°†Markdownè½¬æ¢ä¸ºHTMLå¹¶ç”¨HTMLæ¸²æŸ“ï¼Œä»¥ä¿ç•™åŸºç¡€æ ·å¼
        rendered = False
        if md is not None:
            try:
                html = md.markdown(
                    content,
                    extensions=["extra", "sane_lists", "nl2br"]
                )
                # è®¾ç½®å½“å‰å­—ä½“åæ¸²æŸ“HTML
                pdf.set_font("NotoSansSC", size=base_size)
                pdf.write_html(html)
                rendered = True
            except Exception:
                rendered = False
        # å›é€€ï¼šé€è¡Œå†™å…¥çº¯æ–‡æœ¬
        if not rendered:
            for raw_line in content.split("\n"):
                line = raw_line if raw_line is not None else ""
                if line.strip() == "":
                    pdf.ln(line_height)
                    continue
                pdf.set_x(pdf.l_margin)
                try:
                    pdf.multi_cell(effective_width, line_height, line)
                except Exception:
                    # é€€è·¯1ï¼šæ’å…¥é›¶å®½ç©ºæ ¼ä»¥å¸®åŠ©æ¢è¡Œ
                    try:
                        safe_line = "\u200b".join(list(line))
                        pdf.multi_cell(effective_width, line_height, safe_line)
                    except Exception:
                        # é€€è·¯2ï¼šé™çº§ä¸ºå¯ç¼–ç å­—ç¬¦
                        ascii_fallback = line.encode("latin-1", "replace").decode("latin-1")
                        pdf.multi_cell(effective_width, line_height, ascii_fallback)
        output_buffer = pdf.output(dest="S")
        if isinstance(output_buffer, (bytes, bytearray)):
            pdf_bytes = bytes(output_buffer)
        else:
            # å…¼å®¹æ—§ç‰ˆæœ¬è¿”å› str çš„æƒ…å†µ
            pdf_bytes = str(output_buffer).encode("latin1", errors="replace")
        return pdf_bytes, None
    except Exception as e:
        return None, str(e)


def get_history_records():
    """è·å–æ‰€æœ‰å†å²è®°å½•"""
    import sqlite3
    try:
        conn = sqlite3.connect(HISTORY_DB_PATH)
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS research_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                query TEXT NOT NULL,
                report TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        cursor.execute("""
            SELECT id, query, report, created_at 
            FROM research_history 
            ORDER BY created_at DESC
        """)
        records = cursor.fetchall()
        conn.close()
        return records
    except Exception as e:
        st.error(f"è¯»å–å†å²è®°å½•å¤±è´¥: {str(e)}")
        return []


def get_history_record_by_id(record_id: int):
    """æ ¹æ®IDè·å–å†å²è®°å½•"""
    import sqlite3
    try:
        conn = sqlite3.connect(HISTORY_DB_PATH)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT id, query, report, created_at 
            FROM research_history 
            WHERE id = ?
        """, (record_id,))
        record = cursor.fetchone()
        conn.close()
        return record
    except Exception as e:
        st.error(f"è¯»å–å†å²è®°å½•å¤±è´¥: {str(e)}")
        return None


def delete_history_record(record_id: int):
    """åˆ é™¤å†å²è®°å½•"""
    import sqlite3
    try:
        conn = sqlite3.connect(HISTORY_DB_PATH)
        cursor = conn.cursor()
        cursor.execute("DELETE FROM research_history WHERE id = ?", (record_id,))
        conn.commit()
        conn.close()
        return True
    except Exception as e:
        st.error(f"åˆ é™¤å†å²è®°å½•å¤±è´¥: {str(e)}")
        return False


def format_datetime(created_at):
    """æ ¼å¼åŒ–æ—¶é—´"""
    if isinstance(created_at, str):
        return created_at
    elif hasattr(created_at, 'strftime'):
        return created_at.strftime("%Y-%m-%d %H:%M:%S")
    else:
        return str(created_at)


def main():
    """ä¸»å‡½æ•°"""
    st.set_page_config(
        page_title="WGD Deep Search",
        page_icon="ğŸ”",
        layout="wide"
    )
    
    st.title("WGD Deep Search")
    st.markdown("åŸºäºDeepSeekçš„æ— æ¡†æ¶æ·±åº¦æœç´¢AIä»£ç†")
    
    # APIå¯†é’¥é…ç½®ï¼ˆå¯ç¼–è¾‘å¹¶ä¿å­˜åˆ°SQLiteæ•°æ®åº“ï¼‰
    import sqlite3

    DB_PATH = os.path.join(os.path.dirname(__file__), "apikeys.db")

    # åˆå§‹åŒ–æ•°æ®åº“
    def init_db():
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS api_keys (
                name TEXT PRIMARY KEY,
                value TEXT
            )
        """)
        conn.commit()
        conn.close()
    
    def load_api_key(name):
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute("SELECT value FROM api_keys WHERE name=?", (name,))
        result = cursor.fetchone()
        conn.close()
        if result:
            return result[0]
        return ""
    
    def save_api_key(name, value):
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute("REPLACE INTO api_keys (name, value) VALUES (?, ?)", (name, value))
        conn.commit()
        conn.close()

    # åˆå§‹åŒ–DBï¼ˆåªéœ€è¿è¡Œä¸€æ¬¡ï¼‰
    init_db()
    
    # ä¸»æ ‡ç­¾é¡µï¼šæ–°ç ”ç©¶å’Œå†å²è®°å½•
    main_tab1, main_tab2 = st.tabs(["ğŸ” æ–°ç ”ç©¶", "ğŸ“š å†å²è®°å½•"])
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("é…ç½®")

        st.subheader("APIå¯†é’¥")

        # è¯»å–å·²ä¿å­˜çš„key
        deepseek_default = load_api_key("deepseek")
        tavily_default = load_api_key("tavily")
        
        # åˆå§‹åŒ–APIå¯†é’¥å˜é‡ï¼ˆä»æ•°æ®åº“æˆ–æŸ¥è¯¢å‚æ•°ï¼‰
        # ä¼˜å…ˆä½¿ç”¨æŸ¥è¯¢å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨æ•°æ®åº“ä¸­çš„å€¼
        deepseek_key = deepseek_default
        tavily_key = tavily_default
        
        # ä»æŸ¥è¯¢å‚æ•°è·å–ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if "deepseek_key" in st.query_params:
            param_value = st.query_params.get("deepseek_key")
            deepseek_key = param_value[0] if isinstance(param_value, list) and len(param_value) > 0 else param_value
        if "tavily_key" in st.query_params:
            param_value = st.query_params.get("tavily_key")
            tavily_key = param_value[0] if isinstance(param_value, list) and len(param_value) > 0 else param_value

        # è¡¨å•æ›´æ–°
        # ä¸ºäº†é˜²æ­¢æµè§ˆå™¨å¯†ç ä¿å­˜/ç”Ÿæˆï¼Œä½¿ç”¨è‡ªå®šä¹‰HTMLè¾“å…¥æ¡†å¹¶å…³é—­è‡ªåŠ¨å¡«å……
        import streamlit.components.v1 as components

        with st.form("apikey_form"):

            deepseek_html = f"""
            <input 
                type="password" 
                name="deepseek_key" 
                id="deepseek_key" 
                value="{deepseek_default}" 
                autocomplete="off" 
                autocorrect="off" 
                autocapitalize="off" 
                spellcheck="false" 
                placeholder="DeepSeek API Key"
                style="width: 100%; padding: 0.5em; border-radius: 0.3em; border: 1px solid #ccc;"
                onfocus="this.removeAttribute('autocomplete');"
            >
            """
            tavily_html = f"""
            <input 
                type="password" 
                name="tavily_key" 
                id="tavily_key" 
                value="{tavily_default}" 
                autocomplete="off" 
                autocorrect="off" 
                autocapitalize="off" 
                spellcheck="false" 
                placeholder="Tavily API Key"
                style="width: 100%; padding: 0.5em; border-radius: 0.3em; border: 1px solid #ccc;"
                onfocus="this.removeAttribute('autocomplete');"
            >
            """
            st.markdown("DeepSeek API Key")
            components.html(deepseek_html, height=40)
            st.markdown("Tavily API Key")
            components.html(tavily_html, height=40)

            submitted = st.form_submit_button("ä¿å­˜APIå¯†é’¥")
            # é€šè¿‡QueryString hackï¼ˆæˆ–åˆ©ç”¨streamlit_js_evalçš„jså›ä¼ ï¼‰æ— æ³•ç›´æ¥å–componentsçš„å€¼ï¼Œè¿™é‡Œé‡‡å–streamlitåŸç”Ÿçš„text_inputä¸´æ—¶æ–¹æ¡ˆ
            # ä½†ä¼šå‘ŠçŸ¥ç”¨æˆ·é¿å…ä¿å­˜å¯†ç 
            if submitted:
                # å›è½åˆ°streamlitçš„text_inputï¼Œä»¥ä¾¿å¯ä»¥çœŸæ­£è·å–ç”¨æˆ·è¾“å…¥
                # ä½†é€šè¿‡æ·»åŠ autocomplete="off"å»ºè®®æµè§ˆå™¨ä¸ä¿å­˜å¯†ç 
                new_deepseek_key = st.text_input("DeepSeek API Keyï¼ˆè¯·å‹¿ä¿å­˜å¯†ç ï¼‰", type="password", value=deepseek_default, key="deepseek_form_key", autocomplete="off", label_visibility="collapsed")
                new_tavily_key = st.text_input("Tavily API Keyï¼ˆè¯·å‹¿ä¿å­˜å¯†ç ï¼‰", type="password", value=tavily_default, key="tavily_form_key", autocomplete="off", label_visibility="collapsed")
                save_api_key("deepseek", new_deepseek_key)
                save_api_key("tavily", new_tavily_key)
                # æ›´æ–°å½“å‰ä¼šè¯çš„å€¼
                deepseek_key = new_deepseek_key
                tavily_key = new_tavily_key
                st.success("APIå¯†é’¥å·²ä¿å­˜")
                # é‡æ–°åŠ è½½æ•°æ®åº“ä¸­çš„å€¼ï¼ˆç”¨äºä¸‹æ¬¡è¿è¡Œï¼‰
                deepseek_default = load_api_key("deepseek")
                tavily_default = load_api_key("tavily")
        
        # é«˜çº§é…ç½®
        st.subheader("é«˜çº§é…ç½®")
        max_reflections = st.slider("åæ€æ¬¡æ•°", 1, 5, 2)
        max_search_results = st.slider("æœç´¢ç»“æœæ•°", 1, 10, 3)
        max_content_length = st.number_input("æœ€å¤§å†…å®¹é•¿åº¦", 1000, 50000, 20000)
        
        # æ¨¡å‹é€‰æ‹©
        llm_provider = st.selectbox("LLMæä¾›å•†", ["deepseek", "openai"])
        
        if llm_provider == "deepseek":
            model_name = st.selectbox("DeepSeekæ¨¡å‹", ["deepseek-chat"])
        else:
            model_name = st.selectbox("OpenAIæ¨¡å‹", ["gpt-4o-mini", "gpt-4o"])
            openai_key = st.text_input("OpenAI API Key", type="password",
                                     value="")
    
    # æ–°ç ”ç©¶æ ‡ç­¾é¡µ
    with main_tab1:
        # ä¸»ç•Œé¢
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.header("ç ”ç©¶æŸ¥è¯¢")
            query = st.text_area(
                "è¯·è¾“å…¥æ‚¨è¦ç ”ç©¶çš„é—®é¢˜",
                placeholder="ä¾‹å¦‚ï¼š2025å¹´äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
                height=100
            )
            
            # é¢„è®¾æŸ¥è¯¢ç¤ºä¾‹
            st.subheader("ç¤ºä¾‹æŸ¥è¯¢")
            example_queries = [
                "2025å¹´äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿",
                "æ·±åº¦å­¦ä¹ åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
                "åŒºå—é“¾æŠ€æœ¯çš„æœ€æ–°å‘å±•",
                "å¯æŒç»­èƒ½æºæŠ€æœ¯è¶‹åŠ¿",
                "é‡å­è®¡ç®—çš„å‘å±•ç°çŠ¶"
            ]
            
            selected_example = st.selectbox("é€‰æ‹©ç¤ºä¾‹æŸ¥è¯¢", ["è‡ªå®šä¹‰"] + example_queries)
            if selected_example != "è‡ªå®šä¹‰":
                query = selected_example
        
        with col2:
            st.header("çŠ¶æ€ä¿¡æ¯")
            if 'agent' in st.session_state and hasattr(st.session_state.agent, 'state'):
                progress = st.session_state.agent.get_progress_summary()
                st.metric("æ€»æ®µè½æ•°", progress['total_paragraphs'])
                st.metric("å·²å®Œæˆ", progress['completed_paragraphs'])
                st.progress(progress['progress_percentage'] / 100)
            else:
                st.info("å°šæœªå¼€å§‹ç ”ç©¶")
        
        # æ‰§è¡ŒæŒ‰é’®
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            start_research = st.button("å¼€å§‹ç ”ç©¶", type="primary", use_container_width=True)
        
        # éªŒè¯é…ç½®
        if start_research:
            # é‡æ–°ä»æ•°æ®åº“åŠ è½½APIå¯†é’¥ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°å€¼
            deepseek_key = load_api_key("deepseek")
            tavily_key = load_api_key("tavily")
            
            if not query.strip():
                st.error("è¯·è¾“å…¥ç ”ç©¶æŸ¥è¯¢")
                return
            
            if not deepseek_key and llm_provider == "deepseek":
                st.error("è¯·æä¾›DeepSeek API Key")
                return
            
            if not tavily_key:
                st.error("è¯·æä¾›Tavily API Key")
                return
            
            if llm_provider == "openai" and not openai_key:
                st.error("è¯·æä¾›OpenAI API Key")
                return
            
            # åˆ›å»ºé…ç½®
            config = Config(
                deepseek_api_key=deepseek_key if llm_provider == "deepseek" else None,
                openai_api_key=openai_key if llm_provider == "openai" else None,
                tavily_api_key=tavily_key,
                default_llm_provider=llm_provider,
                deepseek_model=model_name if llm_provider == "deepseek" else "deepseek-chat",
                openai_model=model_name if llm_provider == "openai" else "gpt-4o-mini",
                max_reflections=max_reflections,
                max_search_results=max_search_results,
                max_content_length=max_content_length,
                output_dir="streamlit_reports"
            )
            
            # æ‰§è¡Œç ”ç©¶
            execute_research(query, config)
    
    # å†å²è®°å½•æ ‡ç­¾é¡µ
    with main_tab2:
        st.header("å†å²è®°å½•")
        
        # è·å–æ‰€æœ‰å†å²è®°å½•
        records = get_history_records()
        
        if not records:
            st.info("æš‚æ— å†å²è®°å½•")
        else:
            # åˆ›å»ºè®°å½•é€‰æ‹©å™¨
            record_options = {}
            for record in records:
                record_id, query, report, created_at = record
                # æ ¼å¼åŒ–æ—¶é—´
                time_str = format_datetime(created_at)
                # æ˜¾ç¤ºæ ¼å¼ï¼šID - æŸ¥è¯¢å†…å®¹ - æ—¶é—´
                display_text = f"#{record_id} - {query[:50]}{'...' if len(query) > 50 else ''} - {time_str}"
                record_options[display_text] = record_id
            
            selected_record_key = st.selectbox(
                "é€‰æ‹©å†å²è®°å½•",
                options=["è¯·é€‰æ‹©..."] + list(record_options.keys()),
                key="history_selector"
            )
            
            if selected_record_key != "è¯·é€‰æ‹©...":
                selected_record_id = record_options[selected_record_key]
                record = get_history_record_by_id(selected_record_id)
                
                if record:
                    record_id, query, report, created_at = record
                    
                    # æ˜¾ç¤ºè®°å½•ä¿¡æ¯
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.subheader(f"æŸ¥è¯¢: {query}")
                    with col2:
                        time_str = format_datetime(created_at)
                        st.caption(f"åˆ›å»ºæ—¶é—´: {time_str}")
                        if st.button("åˆ é™¤è®°å½•", key=f"delete_{record_id}", type="secondary"):
                            if delete_history_record(record_id):
                                st.success("è®°å½•å·²åˆ é™¤")
                                st.rerun()
                    
                    # æ˜¾ç¤ºæŠ¥å‘Šå†…å®¹
                    st.divider()
                    st.subheader("æŠ¥å‘Šå†…å®¹")
                    st.markdown(report)
                    
                    # ä¸‹è½½é€‰é¡¹
                    st.divider()
                    st.subheader("ä¸‹è½½æŠ¥å‘Š")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.download_button(
                            label="ä¸‹è½½MarkdownæŠ¥å‘Š",
                            data=report,
                            file_name=f"deep_search_report_{record_id}_{time_str.replace(' ', '_').replace(':', '-')}.md",
                            mime="text/markdown",
                            key=f"download_md_{record_id}"
                        )
                    with col2:
                        # PDFä¸‹è½½ï¼ˆå†å²è®°å½•ï¼‰
                        pdf_bytes, pdf_err = generate_pdf_report(report)
                        st.download_button(
                            label="ä¸‹è½½PDFæŠ¥å‘Š",
                            data=pdf_bytes if pdf_bytes else b"",
                            file_name=f"deep_search_report_{record_id}_{time_str.replace(' ', '_').replace(':', '-')}.pdf",
                            mime="application/pdf",
                            disabled=pdf_bytes is None,
                            key=f"download_pdf_{record_id}"
                        )
                        if pdf_err:
                            st.caption(f"PDFç”Ÿæˆå¤±è´¥ï¼š{pdf_err}")


def execute_research(query: str, config: Config):
    """æ‰§è¡Œç ”ç©¶"""
    try:
        import sqlite3
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # åˆå§‹åŒ–Agent
        status_text.text("æ­£åœ¨åˆå§‹åŒ–Agent...")
        agent = DeepSearchAgent(config)
        st.session_state.agent = agent
        
        progress_bar.progress(10)
        
        # ç”ŸæˆæŠ¥å‘Šç»“æ„
        status_text.text("æ­£åœ¨ç”ŸæˆæŠ¥å‘Šç»“æ„...")
        agent._generate_report_structure(query)
        progress_bar.progress(20)
        
        # å¤„ç†æ®µè½
        total_paragraphs = len(agent.state.paragraphs)
        for i in range(total_paragraphs):
            status_text.text(f"æ­£åœ¨å¤„ç†æ®µè½ {i+1}/{total_paragraphs}: {agent.state.paragraphs[i].title}")
            
            # åˆå§‹æœç´¢å’Œæ€»ç»“
            agent._initial_search_and_summary(i)
            progress_value = 20 + (i + 0.5) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))
            
            # åæ€å¾ªç¯
            agent._reflection_loop(i)
            agent.state.paragraphs[i].research.mark_completed()
            
            progress_value = 20 + (i + 1) / total_paragraphs * 60
            progress_bar.progress(int(progress_value))
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        status_text.text("æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")
        final_report = agent._generate_final_report()
        progress_bar.progress(90)
        
        # ä¿å­˜æŠ¥å‘Š
        status_text.text("æ­£åœ¨ä¿å­˜æŠ¥å‘Š...")
        agent._save_report(final_report)
        progress_bar.progress(100)
        
        status_text.text("ç ”ç©¶å®Œæˆï¼")
        
        # --- æ•°æ®åº“å­˜å‚¨ ---
        try:
            conn = sqlite3.connect(HISTORY_DB_PATH)
            cursor = conn.cursor()
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS research_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    query TEXT NOT NULL,
                    report TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            cursor.execute(
                "INSERT INTO research_history (query, report, created_at) VALUES (?, ?, ?)",
                (query, final_report, datetime.now())
            )
            conn.commit()
            conn.close()
            st.success("å†å²è®°å½•å·²ä¿å­˜")
        except Exception as db_e:
            st.warning(f"å†å²è®°å½•å­˜å‚¨å¤±è´¥: {db_e}")
        # --- æ•°æ®åº“å­˜å‚¨ç»“æŸ ---
        
        # æ˜¾ç¤ºç»“æœ
        display_results(agent, final_report)
        
    except Exception as e:
        st.error(f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


def display_results(agent: DeepSearchAgent, final_report: str):
    """æ˜¾ç¤ºç ”ç©¶ç»“æœ"""
    st.header("ç ”ç©¶ç»“æœ")
    
    # ç»“æœæ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs(["æœ€ç»ˆæŠ¥å‘Š", "è¯¦ç»†ä¿¡æ¯", "ä¸‹è½½"])
    
    with tab1:
        st.markdown(final_report)
    
    with tab2:
        # æ®µè½è¯¦æƒ…
        st.subheader("æ®µè½è¯¦æƒ…")
        for i, paragraph in enumerate(agent.state.paragraphs):
            with st.expander(f"æ®µè½ {i+1}: {paragraph.title}"):
                st.write("**é¢„æœŸå†…å®¹:**", paragraph.content)
                st.write("**æœ€ç»ˆå†…å®¹:**", paragraph.research.latest_summary[:300] + "..." 
                        if len(paragraph.research.latest_summary) > 300 
                        else paragraph.research.latest_summary)
                st.write("**æœç´¢æ¬¡æ•°:**", paragraph.research.get_search_count())
                st.write("**åæ€æ¬¡æ•°:**", paragraph.research.reflection_iteration)
        
        # æœç´¢å†å²
        st.subheader("æœç´¢å†å²")
        all_searches = []
        for paragraph in agent.state.paragraphs:
            all_searches.extend(paragraph.research.search_history)
        
        if all_searches:
            for i, search in enumerate(all_searches):
                with st.expander(f"æœç´¢ {i+1}: {search.query}"):
                    st.write("**URL:**", search.url)
                    st.write("**æ ‡é¢˜:**", search.title)
                    st.write("**å†…å®¹é¢„è§ˆ:**", search.content[:200] + "..." if len(search.content) > 200 else search.content)
                    if search.score:
                        st.write("**ç›¸å…³åº¦è¯„åˆ†:**", search.score)
    
    with tab3:
        # ä¸‹è½½é€‰é¡¹
        st.subheader("ä¸‹è½½æŠ¥å‘Š")
        
        # Markdownä¸‹è½½
        st.download_button(
            label="ä¸‹è½½MarkdownæŠ¥å‘Š",
            data=final_report,
            file_name=f"deep_search_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown"
        )
        
        # PDFä¸‹è½½
        pdf_bytes, pdf_error = generate_pdf_report(final_report)
        
        st.download_button(
            label="ä¸‹è½½PDFæŠ¥å‘Š",
            data=pdf_bytes if pdf_bytes else b"",
            file_name=f"deep_search_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf",
            mime="application/pdf",
            disabled=pdf_bytes is None
        )
        if pdf_error:
            st.error(f"ç”ŸæˆPDFæŠ¥å‘Šå¤±è´¥: {pdf_error}")
        
        # JSONçŠ¶æ€ä¸‹è½½
        state_json = agent.state.to_json()
        st.download_button(
            label="ä¸‹è½½çŠ¶æ€æ–‡ä»¶",
            data=state_json,
            file_name=f"deep_search_state_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )


if __name__ == "__main__":
    main()
